{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pyterrier\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "#create a ColBERT ranking factory based on the pretrained checkpoint\n",
    "from pyterrier_colbert.ranking import ColBERTFactory\n",
    "pytcolbert = ColBERTFactory(\"http://www.dcs.gla.ac.uk/~craigm/ecir2021-tutorial/colbert_model_checkpoint.zip\", \"./msmarco_index\", \"msmarco\", gpu=True)\n",
    "\n",
    "# Download and initialize the msmarco dataset\n",
    "msmarco_ds = pt.get_dataset(\"msmarco_passage\")\n",
    "\n",
    "# Get list of usable queries that have a corresponding relevant in our limited index\n",
    "qids = list(msmarco_ds.get_qrels(\"dev\").loc[msmarco_ds.get_qrels(\"dev\")['docno'].astype(int) < 100000]['qid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ir_measures import RR\n",
    "\n",
    "results = []\n",
    "\n",
    "# Run document pruning experiments from no pruning to 100% pruning at 5% increments\n",
    "for p in np.arange(0.0, 1.01, 0.05):\n",
    "    token_ids = pytcolbert.top_p_tokens(p)\n",
    "    dense_e2e = pytcolbert.end_to_end(token_ids if p != 0 else None)\n",
    "\n",
    "    results += [pt.Experiment(\n",
    "        [dense_e2e],\n",
    "        msmarco_ds.get_topics(\"dev\").loc[msmarco_ds.get_topics(\"dev\")['qid'].str.contains('|'.join(qids), na=False)],\n",
    "        msmarco_ds.get_qrels(\"dev\"),\n",
    "        eval_metrics=[\"map\", RR@10],\n",
    "        names=[f\"ColBERT ({p=:0.2f})\"]\n",
    "    )]\n",
    "\n",
    "    print(results[-1])\n",
    "\n",
    "    # Must delete dense_e2e value to free GPU memory\n",
    "    del dense_e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_measures import RR\n",
    "\n",
    "# Compare no pruning with p=0.5\n",
    "dense_e2e_p0 = pytcolbert.end_to_end()\n",
    "\n",
    "token_ids_p05 = pytcolbert.top_p_tokens(0.5)\n",
    "dense_e2e_p05 = pytcolbert.end_to_end(token_ids_p05)\n",
    "\n",
    "pt.Experiment(\n",
    "    [dense_e2e_p0, dense_e2e_p05],\n",
    "    msmarco_ds.get_topics(\"dev\").loc[msmarco_ds.get_topics(\"dev\")['qid'].str.contains('|'.join(qids), na=False)],\n",
    "    msmarco_ds.get_qrels(\"dev\"),\n",
    "    eval_metrics=[\"map\", RR@10],\n",
    "    baseline=0,\n",
    "    names=[\"p=0.0\", \"p=0.5\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of BERT tokens \n",
    "ids = pytcolbert.unique_token_ids\n",
    "\n",
    "bert_ids = []\n",
    "for id, tok in zip(ids, pytcolbert.token_ids_to_strings(ids)):\n",
    "    if tok.startswith('[') and tok.endswith(']'):\n",
    "        print(tok, id)\n",
    "        bert_ids += [id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to only prune '[CLS]' and '[SEP]'\n",
    "bert_ids = [101, 102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_measures import RR\n",
    "\n",
    "# Compare the effectiveness of the model before and after only BERT tokens are pruned\n",
    "dense_e2e = pytcolbert.end_to_end()\n",
    "dense_e2e_bert_pruned = pytcolbert.end_to_end(bert_ids)\n",
    "\n",
    "pt.Experiment(\n",
    "    [dense_e2e, dense_e2e_bert_pruned],\n",
    "    msmarco_ds.get_topics(\"dev\").loc[msmarco_ds.get_topics(\"dev\")['qid'].str.contains('|'.join(qids), na=False)],\n",
    "    msmarco_ds.get_qrels(\"dev\"),\n",
    "    eval_metrics=[\"map\", RR@10],\n",
    "    baseline=0,\n",
    "    names=[\"No Pruning\", \"BERT Tokens Pruned\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
